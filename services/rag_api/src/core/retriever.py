import functools
from typing import List
from langchain_core.prompts import ChatPromptTemplate
from pydantic import BaseModel, Field
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langchain_upstage import ChatUpstage
from langchain_tavily import TavilySearch
from langchain_community.tools.tavily_search import TavilyAnswer # TavilyAnswerëŠ” ì§ˆë¬¸ì— ëŒ€í•œ ì§ì ‘ì ì¸ ë‹µë³€ì„ ìƒì„±

import os 
from dotenv import load_dotenv
ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..', '..')) # 5ë‹¨ê³„ ìœ„ë¡œ ì´ë™
load_dotenv(os.path.join(ROOT_DIR, '.env'))
UPSTAGE_API_KEY = os.getenv('UPSTAGE_API_KEY')
TAVILY_SEARCH = os.getenv('TAVILY_SEARCH')

def mock_rag_retrieval(paper_title: str) -> List[str]:
    """Vector Storeì—ì„œ ê´€ë ¨ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•˜ëŠ” RAG Retriever ëª¨ì˜ í•¨ìˆ˜."""
    print(f"ğŸ” Vector Store ê²€ìƒ‰ (Retrieve): '{paper_title}' ê¸°ë°˜ í›„ì† ë…¼ë¬¸")
    return ["í›„ì† ë…¼ë¬¸ A (from Vector Store)", "í›„ì† ë…¼ë¬¸ B (from Vector Store)"]

# 1. í‚¤ì›Œë“œ ì¶”ì¶œì„ ìœ„í•œ ë°ì´í„° êµ¬ì¡° ì •ì˜ (Pydantic ëª¨ë¸)
class Keywords(BaseModel):
    """A list of keywords extracted from the user's question."""
    keywords: List[str] = Field(description="ì‚¬ìš©ì ì§ˆë¬¸ì—ì„œ ì¶”ì¶œëœ í•µì‹¬ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸")


def augment_prompt(question: str, llm_api_key: str, tavily_search_key: str) -> str:
    """ì‚¬ìš©ì promptì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì—¬ tavily searchë¡œ ì¦ê°•í•œ í›„, ì˜ì–´ë¡œ ë²ˆì—­í•˜ì—¬ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜
    1. Upstageì˜ solar-mini LLM ëª¨ë¸ì„ ì‚¬ìš©í•´ questionìœ¼ë¡œë¶€í„° í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì—¬ë¼. ì´ë•Œ, LLMì˜ ë‹µë³€ì´ List[str] ì´ ë˜ë„ë¡ í˜•ì‹ì„ ì œí•œí•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì˜ ì‘ì„±í•˜ì—¬ë¼. ë˜ëŠ” Langchainì—ì„œ OutputFixingParserì™€ ê°™ì€ í´ë˜ìŠ¤ë¥¼ í™œìš©í•˜ì—¬ ì¶œë ¥ í˜•ì‹ì„ ì œí•œí•˜ì—¬ë¼.

    2. 1ë²ˆì—ì„œ êµ¬í•œ í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸ì˜ ê° ë‹¨ì–´ë“¤ì„ tavily-search ë¥¼ ì‚¬ìš©í•´ ê° í‚¤ì›Œë“œì— ëŒ€í•´ í•œ ì¤„ì§œë¦¬ ë¶€ê°€ì„¤ëª…ì„ êµ¬í•˜ì—¬ë¼.

    3. questionì˜ í‚¤ì›Œë“œì— 2ë²ˆì—ì„œ êµ¬í•œ ë¶€ê°€ì„¤ëª…ì„ í‚¤ì›Œë“œ ë‹¨ì–´ ë’¤ì— ê´„í˜¸ ì•ˆì— ì¶”ê°€í•˜ì—¬ë¼.
    e.g. ê¸°ì¡´ question : Downstream taskì— ëŒ€í•´ ëª¨ë¸ì˜ ì¬ì‚¬ìš©ì„±ì„ í–¥ìƒì‹œí‚¨ í›„ì†ë…¼ë¬¸ì„ ì•Œë ¤ì¤˜.
        augmented_question : Downstream task(AIì™€ ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ íŠ¹ì • ì‘ì—…ì— ë§ê²Œ ì¡°ì •í•˜ì—¬ í™œìš©í•˜ëŠ” ê³¼ì •)ì— ëŒ€í•´ ëª¨ë¸ì˜ ì¬ì‚¬ìš©ì„±(ì´ë¯¸ ê°œë°œëœ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ ë‹¤ë¥¸ ë¬¸ì œë‚˜ í™˜ê²½ì— ì ìš©í•˜ì—¬ í™œìš©í•˜ëŠ” ê²ƒì„ ì˜ë¯¸)ì„ í–¥ìƒì‹œí‚¨ í›„ì†ë…¼ë¬¸ì„ ì•Œë ¤ì¤˜.

    4. Upstageì˜ solar-pro2 LLM ëª¨ë¸ì„ ì‚¬ìš©í•´ questionì„ ì˜ì–´ë¡œ ë²ˆì—­í•˜ì—¬ return

    :param str question: user prompt
    :param str llm_api_key: Upstage API Key
    :return str: augmented prompt & translated to English
    """
    # 1. solar-mini ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ
    llm_mini = ChatUpstage(api_key=llm_api_key, model='solar-pro2')
    # JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥ì„ íŒŒì‹±í•˜ëŠ” íŒŒì„œ ì„¤ì •
    parser = JsonOutputParser(pydantic_object=Keywords)
    # í‚¤ì›Œë“œ ì¶”ì¶œì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
    keyword_prompt = ChatPromptTemplate.from_template(
        """You are an expert in extracting keywords from a text.
Extract the main keywords from the following user question.
Your output must be a JSON object with a single key 'keywords' containing a list of the extracted keywords.
Exclude keywords related to 'follow-up papers', 'í›„ì† ë…¼ë¬¸'.

Question: {question}

{format_instructions}"""
    )
    # LCELì„ ì‚¬ìš©í•´ í‚¤ì›Œë“œ ì¶”ì¶œ ì²´ì¸ êµ¬ì„±
    keyword_chain = keyword_prompt | llm_mini | parser
    # ì²´ì¸ ì‹¤í–‰
    response = keyword_chain.invoke({
        "question": question,
        "format_instructions": parser.get_format_instructions()
    })
    keywords = response['keywords']
    print(f"âœ… ì¶”ì¶œëœ í‚¤ì›Œë“œ: {keywords}")

    # --- 2ë‹¨ê³„: Tavily Searchë¡œ ê° í‚¤ì›Œë“œì— ëŒ€í•œ ë¶€ê°€ì„¤ëª… ê²€ìƒ‰ ---
    # Tavily Search ë„êµ¬ ì´ˆê¸°í™”
    search = TavilySearch(tavily_api_key=tavily_search_key, max_results=1)
    keyword_definitions = {}

    # print("\n--- 2. í‚¤ì›Œë“œ ì •ì˜ ê²€ìƒ‰ ì¤‘... ---")
    for keyword in keywords:
        # ê° í‚¤ì›Œë“œì— ëŒ€í•œ í•œ ì¤„ ì •ì˜ë¥¼ ì–»ê¸° ìœ„í•´ êµ¬ì²´ì ì¸ ì¿¼ë¦¬ ìƒì„±
        search_query = f'Machine Learning, Deep Learning, AIì™€ ê´€ë ¨í•˜ì—¬ "{keyword}"ì— ëŒ€í•œ í•œ ì¤„ ì •ì˜'
        search_result = search.invoke(search_query)
        
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ìˆê³ , content í‚¤ê°€ ì¡´ì¬í•˜ë©´ ì •ì˜ ì¶”ì¶œ
        if search_result and 'content' in search_result['results'][0]:
            definition = search_result['results'][0]['content']
            keyword_definitions[keyword] = definition
        else:
            keyword_definitions[keyword] = ""

    # --- 3ë‹¨ê³„: keyword:definition pair formatting ---
    keydef_pair = ""
    for keyword, definition in keyword_definitions.items():
        keydef_pair += f"- {keyword}: {definition}\n"
    print("âš™ï¸key def pair:", keydef_pair)

    # --- 4ë‹¨ê³„: Upstage solar-pro2 LLMì„ ì‚¬ìš©í•˜ì—¬ ì˜ì–´ë¡œ ë²ˆì—­ ---
    
    # solar-pro2 ëª¨ë¸ ì´ˆê¸°í™”
    llm_pro = ChatUpstage(api_key=llm_api_key, model="solar-pro2")
    
    # ë²ˆì—­ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ì •ì˜
    translate_prompt = ChatPromptTemplate.from_messages([
        ("system","You are a professional translator. Translate the following Korean text into English."),
        ('user',"""Translate the given text into English following these rules:
1. You will be given a list of keyword: definition pairs. Whenever a keyword appears in the text and you translate it into English, you must include its corresponding definition in parentheses immediately after the translated keyword.
Example: If you are given key1: def1 and the text says â€œkey1ì„ ë”°ë¥´ëŠ”â€, you should translate it as key1(def1) is.
2. Your response must contain only the translated English text, with no additional explanations or extra words.

Keyword:Definition pairs:
{keydef_pair}
Text: {text_to_translate}""")]
    )
    
    # ì¶œë ¥ì„ ë¬¸ìì—´ë¡œ íŒŒì‹±í•˜ëŠ” íŒŒì„œ ì„¤ì •
    output_parser = StrOutputParser()
    
    # LCELì„ ì‚¬ìš©í•´ ë²ˆì—­ ì²´ì¸ êµ¬ì„±
    translate_chain = translate_prompt | llm_pro | output_parser
    
    print("\n--- 4. ì˜ì–´ë¡œ ë²ˆì—­ ì¤‘... ---")
    # ì²´ì¸ ì‹¤í–‰
    final_result = translate_chain.invoke({"keydef_pair":keydef_pair, "text_to_translate": question})
    print("âœ… ë²ˆì—­ ì™„ë£Œ!")
    return final_result


if __name__ == "__main__":
    import os 
    from dotenv import load_dotenv
    ROOT_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..', '..', '..')) # 5ë‹¨ê³„ ìœ„ë¡œ ì´ë™
    print(ROOT_DIR)
    load_dotenv(os.path.join(ROOT_DIR, '.env'))
    UPSTAGE_API_KEY = os.getenv("UPSTAGE_API_KEY")
    TAVILY_SEARCH = os.getenv("TAVILY_SEARCH")
    print(UPSTAGE_API_KEY, TAVILY_SEARCH)

    test_question = "Downstream taskì— ëŒ€í•´ ëª¨ë¸ì˜ ì¬ì‚¬ìš©ì„±ì„ í–¥ìƒì‹œí‚¨ í›„ì†ë…¼ë¬¸ì„ ì•Œë ¤ì¤˜."
    print(f"\n--- ì›ë³¸ ì§ˆë¬¸ --- \n{test_question}\n")

    # í•¨ìˆ˜ ì‹¤í–‰
    augmented_and_translated_prompt = augment_prompt(
        question=test_question,
        llm_api_key=UPSTAGE_API_KEY,
        tavily_search_key=TAVILY_SEARCH
    )

    print("\n========================================")
    print("    âœ¨ ìµœì¢… ë²ˆì—­ëœ ì¦ê°• í”„ë¡¬í”„íŠ¸ âœ¨")
    print("========================================")
    print(augmented_and_translated_prompt)